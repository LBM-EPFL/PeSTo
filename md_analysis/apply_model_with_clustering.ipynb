{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increased-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import mdtraj_utils as mdu\n",
    "from CLoNe.clone import CLoNe\n",
    "from src.structure import clean_structure, tag_hetatm_chains, split_by_chain, filter_non_atomic_subunits, remove_duplicate_tagged_subunits, concatenate_chains, atom_select, data_to_structure, encode_bfactor\n",
    "from src.data_encoding import config_encoding, encode_structure, encode_features, extract_topology, extract_all_contacts, std_elements, std_resnames, std_names\n",
    "from src.dataset import collate_batch_features\n",
    "from src.structure_io import save_pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fe6311-91b7-4697-8ef0-7670cd5e41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj_to_struct(traj):\n",
    "    df = traj.topology.to_dataframe()[0]\n",
    "    return {\n",
    "        \"xyz\": np.transpose(traj.xyz, (1,0,2))*1e1,\n",
    "        \"name\": df[\"name\"].values,\n",
    "        \"element\": df[\"element\"].values,\n",
    "        \"resname\": df[\"resName\"].values,\n",
    "        \"resid\": df[\"resSeq\"].values,\n",
    "        \"het_flag\": np.array(['A']*traj.xyz.shape[1]),\n",
    "        \"chain_name\": df[\"chainID\"].values,\n",
    "        \"icode\": np.array([\"\"]*df.shape[0]),\n",
    "    }\n",
    "\n",
    "\n",
    "def process_structure(structure):\n",
    "    # process structure\n",
    "    structure = clean_structure(structure)\n",
    "\n",
    "    # update molecules chains\n",
    "    structure = tag_hetatm_chains(structure)\n",
    "\n",
    "    # split structure\n",
    "    subunits = split_by_chain(structure)\n",
    "\n",
    "    # remove non atomic structures\n",
    "    subunits = filter_non_atomic_subunits(subunits)\n",
    "\n",
    "    # remove duplicated molecules and ions\n",
    "    subunits = remove_duplicate_tagged_subunits(subunits)\n",
    "    \n",
    "    return subunits\n",
    "\n",
    "\n",
    "def superpose_transform(xyz_ref, xyz):\n",
    "    # centering\n",
    "    t = np.expand_dims(np.mean(xyz,axis=1),1)\n",
    "    t_ref = np.expand_dims(np.mean(xyz_ref,axis=1),1)\n",
    "\n",
    "    # SVD decomposition\n",
    "    U, S, Vt = np.linalg.svd(np.matmul(np.swapaxes(xyz_ref-t_ref,1,2), xyz-t))\n",
    "\n",
    "    # reflection matrix\n",
    "    Z = np.zeros(U.shape) + np.expand_dims(np.eye(U.shape[1], U.shape[2]),0)\n",
    "    Z[:,-1,-1] = np.linalg.det(U) * np.linalg.det(Vt)\n",
    "\n",
    "    R = np.matmul(np.swapaxes(Vt,1,2), np.matmul(Z, np.swapaxes(U,1,2)))\n",
    "\n",
    "    return t_ref, t, R\n",
    "\n",
    "\n",
    "def superpose(xyz_ref, xyz):\n",
    "    # centering\n",
    "    t = np.expand_dims(np.mean(xyz,axis=1),1)\n",
    "    t_ref = np.expand_dims(np.mean(xyz_ref,axis=1),1)\n",
    "\n",
    "    # SVD decomposition\n",
    "    U, S, Vt = np.linalg.svd(np.matmul(np.swapaxes(xyz_ref-t_ref,1,2), xyz-t))\n",
    "\n",
    "    # reflection matrix\n",
    "    Z = np.zeros(U.shape) + np.expand_dims(np.eye(U.shape[1], U.shape[2]),0)\n",
    "    Z[:,-1,-1] = np.linalg.det(U) * np.linalg.det(Vt)\n",
    "\n",
    "    R = np.matmul(np.swapaxes(Vt,1,2), np.matmul(Z, np.swapaxes(U,1,2)))\n",
    "\n",
    "    return xyz_ref-t_ref, np.matmul(xyz-t, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d81f4a-bd95-494e-82d0-23b8e887094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "# R3\n",
    "#save_path = \"save/i_v3_0_2021-05-27_14-27\"  # 89\n",
    "#save_path = \"save/i_v3_1_2021-05-28_12-40\"  # 90\n",
    "# R4\n",
    "#save_path = \"save/i_v4_0_2021-09-07_11-20\"  # 89\n",
    "save_path = \"save/i_v4_1_2021-09-07_11-21\"  # 91\n",
    "\n",
    "# select saved model\n",
    "model_filepath = os.path.join(save_path, 'model_ckpt.pt')\n",
    "#model_filepath = os.path.join(save_path, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded53d36-bdfa-46e1-88f9-667eb66da076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add module to path\n",
    "if save_path not in sys.path:\n",
    "    sys.path.insert(0, save_path)\n",
    "    \n",
    "# load functions\n",
    "from config import config_model, config_data\n",
    "from data_handler import Dataset\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d969b0fd-9b2f-4194-ba18-a09243537b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device\n",
    "device = pt.device(\"cuda\")\n",
    "\n",
    "# create model\n",
    "model = Model(config_model)\n",
    "\n",
    "# reload model\n",
    "model.load_state_dict(pt.load(model_filepath, map_location=pt.device(\"cpu\")))\n",
    "\n",
    "# set model to inference\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "streaming-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "pdbids = [\"1JTG\",\"1CLV\",\"1Z0K\",\"1AK4\",\"1R6Q\",\"1D6R\",\"2I25\",\"3F1P\",\"1R0R\",\"1E96\",\"1GPW\",\"1RKE\",\"1FLE\",\"2O3B\",\"3SGQ\",\"1ZHH\",\"1CGI\",\"2UUY\",\"2HQS\",\"2OOB\"]\n",
    "mdids = [\"uR\", \"uL\"]\n",
    "\n",
    "# setup data connector\n",
    "dc = mdu.data.DataConnector(\"database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0c136-1c48-40fc-b93b-a6c0717dc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters\n",
    "n_skip = 100\n",
    "p_thr = 0.5\n",
    "pdc = 2\n",
    "n_resize = 4\n",
    "\n",
    "results = []\n",
    "for pdbid in pdbids:\n",
    "    # load reference\n",
    "    dc.load_reference(pdbid, \"C\")\n",
    "\n",
    "    # convert and process structure\n",
    "    struct_ref = traj_to_struct(dc[pdbid][\"C\"][\"traj_ref\"])\n",
    "    struct_ref['xyz'] = struct_ref['xyz'][:,0]\n",
    "    subunits_ref = process_structure(struct_ref)\n",
    "\n",
    "    # find interfaces\n",
    "    contacts = extract_all_contacts(subunits_ref, 5.0, device=device)\n",
    "    \n",
    "    # for each md\n",
    "    for mdid in mdids:\n",
    "        # debug print\n",
    "        print(pdbid, mdid)\n",
    "\n",
    "        # load trajectory\n",
    "        dc.load_trajectory(pdbid, mdid)\n",
    "\n",
    "        # convert to structure\n",
    "        structure = traj_to_struct(dc[pdbid][mdid]['traj'])\n",
    "\n",
    "        # process structure\n",
    "        subunits = process_structure(structure)\n",
    "\n",
    "        # concatenate subunits\n",
    "        structure = concatenate_chains(subunits)\n",
    "\n",
    "        # encode structure and features\n",
    "        X_traj, M = encode_structure(structure)\n",
    "        q_all = pt.cat(encode_features(structure), dim=1)\n",
    "        q = encode_features(structure)[0]\n",
    "\n",
    "        # extract topology\n",
    "        ids_topk, D_topk, R_topk, D, R = extract_topology(X_traj[:,0], 64)\n",
    "\n",
    "        # pack data and setup sink (IMPORTANT)\n",
    "        _, ids_topk, q, M = collate_batch_features([[X_traj[:,0], ids_topk, q, M]])\n",
    "\n",
    "        # run model\n",
    "        P, t = [], []\n",
    "        with pt.no_grad():\n",
    "            for i in tqdm(range(0, X_traj.shape[1], n_skip)):\n",
    "                # extract frame coordinates\n",
    "                X = X_traj[:,i]\n",
    "\n",
    "                # make prediction\n",
    "                z = model(X.to(device), ids_topk.to(device), q.to(device), M.float().to(device))\n",
    "                #p = pt.sigmoid(z).flatten()\n",
    "                p = pt.sigmoid(z)[:,0].flatten()\n",
    "\n",
    "                # store results\n",
    "                P.append(p.detach().cpu().numpy())\n",
    "                t.append(dc[pdbid][mdid]['traj'].time[i])\n",
    "\n",
    "        # pack results\n",
    "        P = np.array(P)\n",
    "        t = np.array(t)\n",
    "\n",
    "        # auto-detect chains\n",
    "        ids_sim = mdu.utils.align(dc[pdbid][\"C\"][\"traj_ref\"], dc[pdbid][mdid][\"traj\"], selection=\"all\")\n",
    "        cids_ref = dc[pdbid][\"C\"][\"traj_ref\"].topology.to_dataframe()[0].iloc[ids_sim[:,0]]['chainID'].unique().astype('str')\n",
    "        cids = np.array(list(contacts))\n",
    "\n",
    "        # define labels\n",
    "        ids = contacts[cids_ref[0]][cids[~np.isin(cids, cids_ref)][0]]['ids']\n",
    "        y = np.zeros(M.shape[0])\n",
    "        y[ids[:,0]] = 1.0\n",
    "        y = (np.matmul(y, M.detach().cpu().numpy()) > 0.5).astype(float)\n",
    "\n",
    "        # compute auc\n",
    "        auc = np.array([roc_auc_score(y, p) for p in P])\n",
    "        print(f\"mean auc = {np.mean(auc):.3f}\")\n",
    "\n",
    "        # compute rmsd \n",
    "        rmsd = mdu.utils.rmsd(dc[pdbid][\"C\"][\"traj_ref\"], dc[pdbid][mdid][\"traj\"][::n_skip], selection=\"all\")[0]\n",
    "        \n",
    "        # get atom coordinates for C_alpha for predicted frames\n",
    "        #Xp = atom_select(structure, structure['name'] == \"CA\")['xyz'][:, np.array([i for i in range(0, X_traj.shape[1], n_skip)])].transpose((1,0,2)).copy()\n",
    "        X_traj_slice = X_traj[:, pt.arange(0, X_traj.shape[1], n_skip)]\n",
    "        Xp = (pt.matmul(X_traj_slice.transpose(0,2), M) / pt.sum(M, axis=0).reshape(1,1,-1)).transpose(0,2).transpose(0,1).numpy()\n",
    "        _, Xp = superpose(np.expand_dims(Xp[0],0), Xp)\n",
    "\n",
    "        # weighted centers\n",
    "        #Xc = np.sum(Xp * np.expand_dims(P,2), axis=1) / np.sum(np.expand_dims(P,2),axis=1)\n",
    "        #m = np.ones(Xc.shape[0], dtype=bool)\n",
    "        T = (P > p_thr).astype(np.float32)\n",
    "        m = (np.sum(T, axis=1) > 0.0)\n",
    "        Xc = np.sum(Xp[m] * np.expand_dims(T[m],2), axis=1) / np.sum(np.expand_dims(T[m],2),axis=1)\n",
    "\n",
    "        # weighted distance standard deviations\n",
    "        #s = np.sqrt(np.sum(np.sum(np.square(Xp - np.expand_dims(Xc,1)) * np.expand_dims(P,2), axis=2), axis=1) / np.sum(P, axis=1))\n",
    "\n",
    "        # clustering\n",
    "        clone = CLoNe(pdc=pdc, n_resize=n_resize)\n",
    "        clone.fit(Xc)\n",
    "        ids_c = clone.centers\n",
    "        print(len(ids_c), ids_c)\n",
    "\n",
    "        Xy = np.sum(Xp * y.reshape(1,-1,1), axis=1) / np.sum(y.reshape(1,-1,1),axis=1)\n",
    "\n",
    "        ids_clst = []\n",
    "        for i in range(len(ids_c)):\n",
    "            ids_clst.append(np.where(clone.labels_ == i)[0])\n",
    "\n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(9,9))\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for ids in ids_clst:\n",
    "            ax.scatter(Xc[ids,0], Xc[ids,1], Xc[ids,2], marker='.')\n",
    "        #ax.set_xlim(Xp[:,0].min(), Xp[:,0].max())\n",
    "        #ax.set_ylim(Xp[:,1].min(), Xp[:,1].max())\n",
    "        #ax.set_zlim(Xp[:,2].min(), Xp[:,2].max())\n",
    "        ax.scatter(Xc[ids_c,0], Xc[ids_c,1], Xc[ids_c,2], marker='s', color='k')\n",
    "        ax.scatter(Xy[:,0], Xy[:,1], Xy[:,2], marker='.', color='k')\n",
    "        ax.view_init(30, 210)\n",
    "        plt.show()\n",
    "            \n",
    "        for i, ids in enumerate(ids_clst):\n",
    "            # debug print\n",
    "            #print(\"center_auc={:.2f}, mean_clust_auc={:.2f}, clust_size={}\".format(auc[m][ids_c[i]], np.mean(auc[m][ids]), len(ids)))\n",
    "\n",
    "            # convert input data to structure\n",
    "            xyz_ctr = superpose(X_traj_slice[:,0].unsqueeze(0).numpy(), X_traj_slice[:,m][:,ids_c[i]].unsqueeze(0).numpy())[1][0]\n",
    "            structure = data_to_structure(xyz_ctr, q_all.numpy(), M.numpy(), std_elements, std_resnames, std_names)\n",
    "\n",
    "            # encode bfactor and pack subunits\n",
    "            subunits = {'A': encode_bfactor(structure, P[m][ids_c[i]])}\n",
    "\n",
    "            # save pdb\n",
    "            save_pdb(subunits, \"pdbs_clusters/{}_{}_{}_AUC{}_N{}.pdb\".format(pdbid, mdid, i, int(auc[m][ids_c[i]]*1e2), len(ids)))\n",
    "\n",
    "            # additional prediction informations\n",
    "            p_int = P[m][ids_c[i]][P[m][ids_c[i]] > 0.3]\n",
    "            X_int = Xp[m][ids_c[i]][P[m][ids_c[i]] > 0.3]\n",
    "            r_int = np.sqrt(np.mean(np.sum(np.square(X_int - np.mean(X_int, axis=0).reshape(1,-1)), axis=1)))\n",
    "\n",
    "            # store results\n",
    "            results.append({\n",
    "                \"pdbid\": pdbid,\n",
    "                \"mdid\": mdid,\n",
    "                \"cid\": i,\n",
    "                \"clust_center_auc\": auc[m][ids_c[i]],\n",
    "                \"mean_clust_auc\": np.mean(auc[m][ids]),\n",
    "                \"clust_size\": len(ids),\n",
    "                \"mean_auc\": np.mean(auc),\n",
    "                \"mean_int_p\": np.mean(p_int),\n",
    "                \"std_int_p\": np.std(p_int),\n",
    "                \"max_int_p\": np.max(p_int),\n",
    "                \"r_int\": r_int,\n",
    "            })\n",
    "\n",
    "        # display debug\n",
    "        display(pd.DataFrame(results[-len(ids_c):]))\n",
    "        \n",
    "        # unload data\n",
    "        dc.unload_md(pdbid, mdid)\n",
    "        \n",
    "    # unload data\n",
    "    dc.unload_pdb(pdbid)\n",
    "    \n",
    "# save summary results table\n",
    "pd.DataFrame(results).to_csv(\"interface_clustering_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beec9d0-7e5d-4341-af25-a5224136e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac99cd2-dc2a-4c8a-992a-3f3eb4f42602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65733a5a-cd1a-4838-b329-3f4bc9178492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175183e-6db3-405c-ae2b-b472bd95e1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3d525-982a-43fd-8e17-1012a97661d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f370995-4897-4d53-a617-25ea06fcd6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pesto",
   "language": "python",
   "name": "pesto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
